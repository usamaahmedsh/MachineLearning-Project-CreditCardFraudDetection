{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f60257-2e66-4566-8ef6-e17d95e8e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d63118-3daa-44dc-84f0-82f72ed662cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "df = pd.read_csv('D:\\Lecture Notes\\Machine Learning\\Project\\data\\creditcard.csv')\n",
    "\n",
    "print(\"Data - rows: \", df.shape[0], \"columns: \", df.shape[1])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef3719-e404-4c15-99b8-520fb361e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values \n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def0e58-f8ed-471a-bea0-2e50d258bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for data imbalance\n",
    "\n",
    "class_distribution = df['Class'].value_counts()\n",
    "print(class_distribution)\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'Class', data = df)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.savefig('class_distribution.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Data is highly unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c9cae-5293-490b-95a3-d2223ec100f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing numerical features\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "df.boxplot()\n",
    "plt.xticks(rotation = 45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# All numerical features are standardized (their mean is 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2fe65-eea7-4fa5-873d-0576a9401cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation matrix\n",
    "\n",
    "corr_matrix = df.corr()\n",
    "plt.figure(figsize = (16,10))\n",
    "sns.heatmap(corr_matrix, annot = True, cmap = 'coolwarm', fmt = \".2f\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# There is almost no correlation between V1-V28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15984251-dd27-461c-b524-970cef1857cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check any outliers \n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "sns.boxplot(x = 'Class', y = 'Amount', data = df)\n",
    "plt.title(\"Outliers Detection\")\n",
    "plt.show()\n",
    "\n",
    "tmp_df = df[['Amount','Class']].copy()\n",
    "class_0 = tmp_df.loc[tmp_df['Class'] == 0]['Amount']\n",
    "class_1 = tmp_df.loc[tmp_df['Class'] == 1]['Amount']\n",
    "\n",
    "class_0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44039f-e1b3-426a-9865-cf07f36d7b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1.describe()\n",
    "\n",
    "# real transactions have a larger mean value, larger Q1, smaller Q3 and Q4 and larger outliers;\n",
    "# fraudulent transactions have a smaller Q1 and mean, larger Q4 and smaller outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6effc939-a1bc-482e-a9d3-e3ebbbbd5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data in training/testing \n",
    "\n",
    "x = df.drop('Class', axis = 1)\n",
    "y = df['Class']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "# Scale the parameters\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(x_train)\n",
    "X_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Grid search\n",
    "param_grid = [{'C': [1], 'kernel': ['rbf','linear'], 'gamma': ['scale']}]\n",
    "\n",
    "svm_clf = SVC(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(svm_clf, param_grid, scoring='recall', verbose=2)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_pred = best_svm.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2d5c1-ba2f-4157-b840-e97b23ac91f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report and confusion matrix\n",
    "print(\"Best Model - Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.savefig('confusion_matrix.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b87d2aa-4c10-47a5-b491-5652c9e0a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance \n",
    "\n",
    "# took some help from https://stackoverflow.com/questions/41592661/determining-the-most-contributing-features-for-svm-classifier-in-sklearn\n",
    "\n",
    "feature_names = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\n",
    "       'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\n",
    "       'Amount']\n",
    "\n",
    "def plot_importances(coef, names):\n",
    "    importances = coef\n",
    "    importances, names = zip(*sorted(zip(importances, names)))\n",
    "    plt.barh(range(len(names)), importances, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Features')\n",
    "    plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "plot_importances(best_svm.coef_.ravel(), feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d9c837-982a-4935-a3d5-eda87b9df4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the precision recall curve \n",
    "\n",
    "y_scores = best_svm.decision_function(X_test_scaled)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel('Recall (Sensitivity)')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid(False)\n",
    "plt.savefig('precision_recall_curve.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
